# -*- coding: utf-8 -*-
"""Model Penerapan_Datascience2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZidgiGeqx2xBGGZyOcUfYhvKncRW1-3R

# Proyek Akhir: Menyelesaikan Permasalahan Institusi Pendidikan

- Nama: Muhammad Kaisan Aulia Ridwan
- Email: muhammadkaisan3@gmail.com
- Id Dicoding: A200YBM330

## Persiapan

### Menyiapkan library yang dibutuhkan
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_curve, average_precision_score
from sklearn.preprocessing import label_binarize

from google.colab import drive
drive.mount('/content/drive')

"""### Menyiapkan data yang akan diguankan"""

# Load Data
student_df = pd.read_csv("/content/drive/MyDrive/Dataset/datascience2/data.csv", sep=';')

# Tampilkan info awal
student_df.info()

"""Menggunkan sep, ';'. karena sebelumnya saat tidak memakai semua kolom dianggap string jika tidak ditangani delimiter."""

student_df.head()

student_df.describe()

student_df.head()

"""## Data Understanding"""

# Cek nilai null (bukan NaN string)
student_df.replace("NaN", np.nan, inplace=True)
student_df.replace("nan", np.nan, inplace=True)
student_df.replace("NULL", np.nan, inplace=True)
student_df.replace("null", np.nan, inplace=True)

print("Jumlah missing value per kolom:")
print(student_df.isnull().sum())

# Drop missing values
df_cleaned = student_df.dropna()
print("\nBentuk data setelah drop missing values:", df_cleaned.shape)

student_df.to_csv("Dataset/data_cleaned.csv", index=False)

"""Insight :

- Penghapusan nilai yang hilang (missing values) sebenarnya tidak diperlukan karena data set sudah lengkap. Namun, prosedur ini tetap diterapkan demi memenuhi rutinitas dan protokol yang telah ditetapkan

- Target (Status) kemungkinan diklasifikasikan menjadi Dropout, Enrolled, dan Graduate.

### EDA
"""

# Visualisasi: Histogram
plt.figure(figsize=(14, 8))
df_cleaned.hist(bins=20, figsize=(16, 12), color='skyblue', edgecolor='black')
plt.suptitle("Distribusi Fitur Numerik", fontsize=16)
plt.tight_layout()
plt.show()

# Visualisasi: Pie chart - Status (misal: Dropout)
if 'Status' in df_cleaned.columns:
    status_counts = df_cleaned['Status'].value_counts()
    plt.figure(figsize=(6,6))
    plt.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%', startangle=140, colors=['steelblue', 'orange', 'green'])
    plt.title('Distribusi Status Mahasiswa')
    plt.axis('equal')
    plt.show()
else:
    print("Kolom 'Status' tidak ditemukan di df_cleaned")

plt.figure(figsize=(8,5))
sns.countplot(data=df_cleaned, x='Status', palette='viridis')
plt.title('Jumlah Mahasiswa per Status')
plt.xlabel('Status')
plt.ylabel('Jumlah')
plt.grid(axis='y')
plt.show()

# Heatmap Korelasi
plt.figure(figsize=(16, 12))
df_numeric = df_cleaned.select_dtypes(include=np.number)
sns.heatmap(df_numeric.corr(), annot=True, fmt=".2f", cmap='coolwarm')
plt.title("Heatmap Korelasi Antar Fitur")
plt.show()

# Pairplot fitur numerik
sample_cols = df_numeric.columns[:5].tolist()
sns.pairplot(df_cleaned[sample_cols])
plt.suptitle("Pairplot Beberapa Fitur Numerik", y=1.02)
plt.show()

"""insight :

- Performa Akademik Semester Awal Menjadi Indikator Dropout Paling Kuat
Mahasiswa dengan nilai rendah, banyak mata kuliah yang tidak lulus, atau tidak mengikuti evaluasi di semester 1 dan 2 cenderung lebih berisiko mengalami dropout. Ini menunjukkan bahwa semester awal merupakan periode krusial yang bisa digunakan untuk deteksi dini.

- Faktor Finansial dan Dukungan Sosial Memiliki Dampak Signifikan
Mahasiswa yang memiliki utang, tidak membayar UKT tepat waktu, atau tidak menerima beasiswa lebih rentan dropout. Selain itu, latar belakang keluarga seperti pendidikan dan pekerjaan orang tua ikut berpengaruh, memperkuat pentingnya peran kondisi sosial-ekonomi.

- Kelas Target Tidak Seimbang, dan Perlu Penanganan Khusus dalam Modeling
Sebagian besar mahasiswa berada di kategori “Graduate”, sementara “Dropout” merupakan kelas minoritas. Ini perlu diperhatikan dalam pemilihan model dan metrik evaluasi karena model bisa bias terhadap kelas mayoritas jika tidak ditangani dengan teknik seperti class balancing atau metrik alternatif.

## Data Preparation / Preprocessing
"""

# Encode kategorikal
df_encoded = df_cleaned.copy()
categorical_cols = df_encoded.select_dtypes(include='object').columns
le = LabelEncoder()
for col in categorical_cols:
    df_encoded[col] = le.fit_transform(df_encoded[col])

# Tentukan target
if 'Target' in df_encoded.columns:
    X = df_encoded.drop('Target', axis=1)
    y = df_encoded['Target']
else:
    X = df_encoded.iloc[:, :-1]
    y = df_encoded.iloc[:, -1]

# Scaling
scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

"""Insight :

- Data kategorikal diubah menjadi numerik agar kompatibel dengan algoritma machine learning
Fitur seperti Status, Scholarship_holder, dan Debtor dikonversi ke format numerik menggunakan teknik encoding, sehingga dapat diproses langsung oleh model prediktif tanpa kehilangan informasi kategorikal.

- Standarisasi dilakukan untuk menyamakan skala antar fitur numerik
Kolom seperti Admission_grade, Age_at_enrollment, dan nilai akademik tiap semester memiliki rentang berbeda. Dengan standardisasi, proses pelatihan model menjadi lebih stabil dan hasil prediksi lebih akurat, terutama untuk model seperti SVM dan KNN yang sensitif terhadap skala.

- Data dibagi menjadi train dan test set dengan proporsi 80:20 untuk validasi yang adil
Penggunaan random_state=42 menjamin hasil pembagian data konsisten di setiap eksperimen, sehingga mempermudah reproduksi dan evaluasi model secara objektif.

## Modeling
"""

# Modeling
models = {
    "SVM": SVC(probability=True),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "AdaBoost": AdaBoostClassifier(random_state=42),
    "Extra Trees": ExtraTreesClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(random_state=42),
    "KNN": KNeighborsClassifier()
}

model_scores = {}

for name, model in models.items():
    print(f"\nTraining model: {name}")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    model_scores[name] = acc
    print(f"Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred))

"""Insight :

- Tujuh algoritma machine learning digunakan untuk membandingkan performa prediksi
Model yang diuji mencakup pendekatan linear, distance-based, hingga ensemble: Logistic Regression, Random Forest, KNN, SVM, Gradient Boosting, AdaBoost, dan Extra Trees. Tujuannya untuk menemukan model yang paling optimal terhadap pola data.

- Gradient Boosting dan Logistic Regression tampil sebagai model terbaik dengan akurasi tertinggi
Kedua model ini konsisten mencetak akurasi antara 86% hingga 88%, menunjukkan kemampuannya dalam menangkap hubungan kompleks antara fitur dengan label dropout.

- Semua model menunjukkan performa yang baik dengan akurasi di atas 80%
Ini menandakan bahwa dataset memiliki informasi yang cukup kuat untuk membedakan status mahasiswa, dan preprocessing yang dilakukan mampu meningkatkan kualitas input ke model.

## Evaluation
"""

# Bandingkan Akurasi
score_df = pd.DataFrame(list(model_scores.items()), columns=["Model", "Accuracy"])
score_df = score_df.sort_values(by="Accuracy", ascending=False)

plt.figure(figsize=(10,5))
sns.barplot(data=score_df, x="Accuracy", y="Model", palette="viridis")
plt.title("Perbandingan Akurasi Tiap Model")
plt.xlim(0, 1)
plt.grid(True)
plt.show()

# Cetak model terbaik
best_model_name = score_df.iloc[0]["Model"]
best_accuracy = score_df.iloc[0]["Accuracy"]
print(f"Model terbaik adalah: {best_model_name} dengan akurasi: {best_accuracy:.4f}")

"""Dari semua model, model paling akurat ialah Extra Trees dengan nilai 76.84% yang bisa dibulatkan menjadi 77%"""

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

tree_based_models = ["Random Forest", "Gradient Boosting", "Extra Trees"]

for name in tree_based_models:
    model = models[name]
    importances = pd.Series(model.feature_importances_, index=X.columns)
    importances.nlargest(15).plot(kind='barh')
    plt.title(f"Top 15 Feature Importances - {name}")
    plt.xlabel("Importance")
    plt.gca().invert_yaxis()
    plt.tight_layout()
    plt.show()

try:
    best_model_name = score_df.iloc[0]['Model']
    best_model = models[best_model_name]
    y_score = best_model.predict_proba(X_test) if hasattr(best_model, "predict_proba") else None

    if y_score is not None and len(np.unique(y_test)) == 3:
        labels = np.unique(y_test)
        for i, label in enumerate(labels):
            y_test_bin = (y_test == label).astype(int)
            precision, recall, _ = precision_recall_curve(y_test_bin, y_score[:, i])
            avg_precision = average_precision_score(y_test_bin, y_score[:, i])

            plt.figure(figsize=(8, 6))
            plt.plot(recall, precision, lw=2, label=f"Avg Precision = {avg_precision:.2f}")
            plt.xlabel("Recall")
            plt.ylabel("Precision")
            plt.title(f"Precision-Recall Curve untuk Kelas: {label}")
            plt.legend(loc="lower left")
            plt.grid(True)
            plt.show()
    else:
        print("Model tidak mendukung predict_proba atau jumlah kelas tidak 3.")
except Exception as e:
    print(f"Gagal membuat Precision-Recall Curve untuk semua kelas: {e}")

"""Insight :

- Model memiliki performa sangat baik dalam mengenali kelas Dropout dan Graduate
Precision-Recall Curve menunjukkan bahwa kelas 0 (Dropout) dan kelas 2 (Graduate) memiliki average precision di atas 0.85, dengan kurva yang mulus dan stabil. Ini menunjukkan kemampuan model dalam mendeteksi dua kelas mayoritas secara konsisten.

- Performa rendah pada kelas Enrolled disebabkan oleh ketidakseimbangan jumlah data
Kelas 1 (Enrolled) hanya mencapai average precision sebesar 0.50, dengan kurva yang menurun tajam. Evaluasi melalui confusion matrix menunjukkan bahwa prediksi untuk kelas ini sering tertukar, mengindikasikan bahwa data kelas Enrolled jauh lebih sedikit dibandingkan kelas lain.

- Ketidakseimbangan kelas berdampak signifikan terhadap hasil evaluasi
Walaupun akurasi keseluruhan tinggi, performa model terhadap kelas minoritas seperti Enrolled perlu ditingkatkan menggunakan strategi seperti resampling, penyesuaian threshold, atau penambahan bobot kelas.


"""